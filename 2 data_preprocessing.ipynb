{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_data_path = os.path.join(os.getcwd(), \"outputs\", \"clean_data.csv\")\n",
    "\n",
    "# Revised version on 2025-02-21 and 2025-03-20\n",
    "clean_data_path = os.path.join(os.getcwd(), \"outputs\", \"clean_data_revised.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6724, 179)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_fix = {\n",
    "    \"38-40周血葡萄糖\": pl.Utf8,\n",
    "    \"30.1-37.6周血葡萄糖\": pl.Utf8,\n",
    "    \"10.1-20周促甲状腺激素受体抗体\": pl.Utf8,\n",
    "    \"21-40周促甲状腺激素受体抗体\": pl.Utf8,\n",
    "    \"25.1-32w_脐动脉S/D\": pl.Utf8,\n",
    "    \"18.1-25w_脐动脉RI\": pl.Utf8,\n",
    "    \"1-10周促甲状腺激素受体抗体\": pl.Utf8,\n",
    "    \"1-11.6周糖化血红蛋白\": pl.Utf8,\n",
    "    \"25.1-33.6周γ-谷氨酰转肽酶\": pl.Utf8,\n",
    "    \"22.1-32周乳酸脱氢酶\": pl.Utf8,\n",
    "    \"25.1-33.6周谷丙转氨酶\": pl.Utf8,\n",
    "    \"25.1-33.6周谷草转氨酶\": pl.Utf8,\n",
    "    \"1-10周TGAB\": pl.Utf8,\n",
    "    \"25.1-32w_羊水深度\": pl.Utf8,\n",
    "    \"1-12.6周谷丙转氨酶\": pl.Utf8,\n",
    "    \"18.1-25w_双顶径\": pl.Utf8,\n",
    "    \"13-25周γ-谷氨酰转肽酶\": pl.Utf8,\n",
    "    \"1-22周乳酸脱氢酶\": pl.Utf8,\n",
    "    \"13-25周谷丙转氨酶\": pl.Utf8,\n",
    "    \"13-25周谷草转氨酶\": pl.Utf8,\n",
    "    \"38-40周谷丙转氨酶\": pl.Utf8,\n",
    "    \"32.1-40周乳酸脱氢酶\": pl.Utf8,\n",
    "} # Obtained by trial and error\n",
    "\n",
    "df = pl.read_csv(clean_data_path, infer_schema=True, schema_overrides=columns_to_fix)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for manually identified columns\n",
    "for col in columns_to_fix.keys():\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Column to fix '{col}' not found in the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6724, 157) (6724, 23)\n"
     ]
    }
   ],
   "source": [
    "# Split dataframe into two dataframes: one with columns to fix and the rest\n",
    "df_ok = df.drop(list(columns_to_fix.keys()))\n",
    "ID_col = df_ok.columns[0]\n",
    "\n",
    "df_to_fix = df.select([ID_col] + list(columns_to_fix.keys()))\n",
    "\n",
    "print(df_ok.shape, df_to_fix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Delete features with more empty values than a given threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_columns_with_nulls(df: pl.DataFrame, threshold_percentage: float=0.5):\n",
    "    threshold = threshold_percentage * df.height\n",
    "\n",
    "    # Get null counts for all columns in a single operation\n",
    "    null_counts = df.null_count()\n",
    "\n",
    "    # Create a Series mapping column names to their null counts\n",
    "    null_counts_dict = dict(zip(null_counts.columns, null_counts.row(0)))\n",
    "\n",
    "    # Identify columns to drop\n",
    "    cols_to_drop = [col for col, null_count in null_counts_dict.items() if null_count >= threshold]\n",
    "\n",
    "    # Drop columns iand return the new DataFrame\n",
    "    return df.drop(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6724, 85) (6724, 15)\n"
     ]
    }
   ],
   "source": [
    "df_ok_2 = delete_columns_with_nulls(df_ok)\n",
    "df_to_fix_2 = delete_columns_with_nulls(df_to_fix)\n",
    "print(df_ok_2.shape, df_to_fix_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cast and amend data entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cast_value(value, column_name, row_idx):\n",
    "    '''\n",
    "    Try to cast a value to an integer or float. If it fails, prompt the user to enter a corrected value or set it as null.\n",
    "    '''\n",
    "    while True:\n",
    "        try:\n",
    "            return int(value)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return float(value)\n",
    "            except ValueError:\n",
    "                user_input = input(\n",
    "                    f\"Error casting value '{value}' in column '{column_name}', row {row_idx}. \"\n",
    "                    f\"Enter a corrected value or type 'None'/'Null' to set it as null: \"\n",
    "                ).strip()\n",
    "                \n",
    "                if user_input.lower() in [\"none\", \"null\"]:\n",
    "                    return None\n",
    "                else:\n",
    "                    value = user_input  # Update the value and retry casting\n",
    "                    \n",
    "\n",
    "def fix_values_dtype(df: pl.DataFrame):\n",
    "    # Fix columns\n",
    "    processed_columns = dict()\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column == ID_col:\n",
    "            processed_columns[column] = df[column].to_list()\n",
    "            continue\n",
    "        \n",
    "        processed_values = []\n",
    "        for row_idx, value in enumerate(df[column].to_list(), start=1):\n",
    "            if value is None:\n",
    "                processed_values.append(None)\n",
    "                continue\n",
    "            processed_value = _cast_value(value, column, row_idx)\n",
    "            processed_values.append(processed_value)\n",
    "        \n",
    "        # Check if conversion to all floats is needed (avoid integers and float mixture)\n",
    "        has_floats = any(isinstance(v, float) for v in processed_values)\n",
    "        if has_floats:\n",
    "            processed_values = [\n",
    "                float(v) if v is not None else None \n",
    "                for v in processed_values\n",
    "            ]\n",
    "        \n",
    "        processed_columns[column] = processed_values\n",
    "\n",
    "    # Create a new DataFrame with the processed data\n",
    "    return pl.DataFrame(processed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6724, 15)\n"
     ]
    }
   ],
   "source": [
    "df_to_fix_3 = fix_values_dtype(df_to_fix_2)\n",
    "print(df_to_fix_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6724, 85) (6724, 15)\n"
     ]
    }
   ],
   "source": [
    "# Validate row counts\n",
    "print(df_ok_2.shape, df_to_fix_3.shape)\n",
    "assert df_ok_2.height == df_to_fix_3.height, \"Row counts do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6724, 99)\n"
     ]
    }
   ],
   "source": [
    "# Join the two DataFrames on ID\n",
    "merged_df = df_ok_2.join(df_to_fix_3, on=ID_col, how=\"inner\")\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Fix Faulty Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6724, 99)\n"
     ]
    }
   ],
   "source": [
    "# Fix faulty entries in the \"身高\" column. If the data value is less than 150, set it to empty. \n",
    "merged_df = merged_df.with_columns(\n",
    "    pl.when(pl.col(\"身高\") < 150.0)\n",
    "    .then(None)\n",
    "    .otherwise(pl.col(\"身高\"))\n",
    "    .alias(\"身高\")\n",
    ")\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Divide dataframes into numeric and non-numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data_path = os.path.join(os.getcwd(), \"outputs\", \"raw_numeric_data.csv\")\n",
    "non_numeric_data_path = os.path.join(os.getcwd(), \"outputs\", \"raw_non_numeric_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6724, 42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all columns that are neither float nor integer\n",
    "_df_not_float = merged_df.select([col for col in merged_df.columns if merged_df[col].dtype != pl.Float64])\n",
    "df_not_number = _df_not_float.select([col for col in _df_not_float.columns if _df_not_float[col].dtype != pl.Int64])\n",
    "df_not_number.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6724, 58)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete non-numeric columns from the merged DataFrame (except the ID column)\n",
    "columns_to_drop = [col for col in df_not_number.columns if col != ID_col]\n",
    "df_numeric = merged_df.drop(columns_to_drop)\n",
    "df_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save resulting dataframes to CSV files\n",
    "df_numeric.write_csv(numeric_data_path)\n",
    "df_not_number.write_csv(non_numeric_data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thyroid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
